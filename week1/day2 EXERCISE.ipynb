{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to create high-quality content such as images, videos, and text. This can be applied in fields like advertising, marketing, and media production.\n",
      "2. **Product Design**: Generative AI can help design new products, such as fashion items, furniture, and even entire buildings. This can streamline the product development process and reduce costs.\n",
      "3. **Personalized Recommendations**: Generative AI can analyze customer behavior and preferences to generate personalized product recommendations for e-commerce websites and other online platforms.\n",
      "4. **Chatbots and Virtual Assistants**: Generative AI can be used to create more sophisticated chatbots and virtual assistants that can understand natural language and respond accordingly.\n",
      "5. **Data Analysis and Visualization**: Generative AI can help analyze large datasets and create visualizations that can provide insights into trends, patterns, and correlations.\n",
      "6. **Marketing Automation**: Generative AI can automate repetitive marketing tasks such as lead generation, email campaigns, and social media content creation.\n",
      "7. **Supply Chain Optimization**: Generative AI can optimize supply chain operations by predicting demand, identifying bottlenecks, and recommending logistics improvements.\n",
      "8. **Financial Modeling**: Generative AI can help create more accurate financial models by analyzing large datasets and generating forecasts for revenue, expenses, and other key performance indicators (KPIs).\n",
      "9. **Healthcare Diagnosis**: Generative AI can be used to analyze medical images, diagnose diseases, and develop personalized treatment plans.\n",
      "10. **Customer Service**: Generative AI can help create more effective customer service systems by analyzing customer feedback, identifying patterns, and generating personalized responses.\n",
      "\n",
      "Some specific examples of business applications of Generative AI include:\n",
      "\n",
      "* Google's Image Generator: uses Generative AI to generate high-quality images for use in advertising and marketing campaigns.\n",
      "* Amazon's Product Recommendations: uses Generative AI to analyze customer behavior and provide personalized product recommendations.\n",
      "* IBM's Watson Assistant: uses Generative AI to create more sophisticated chatbots and virtual assistants.\n",
      "* NVIDIA's Deep Learning Platform: uses Generative AI to optimize computer vision and machine learning applications in various industries.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative applications across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI can generate high-quality content such as articles, social media posts, product descriptions, and even entire books. This can save time and resources for businesses, while also improving the consistency and quality of their content.\n",
      "2. **Product Design**: Generative AI can be used to design new products, such as furniture, clothing, and electronics. It can generate 3D models, textures, and colors, making it an ideal tool for product designers and manufacturers.\n",
      "3. **Marketing Automation**: AI-powered chatbots can automate customer service, lead generation, and marketing campaigns, helping businesses to personalize their interactions with customers and improve their overall marketing strategy.\n",
      "4. **Data Analysis**: Generative AI algorithms can analyze large datasets and generate insights, patterns, and predictions, which can help businesses make data-driven decisions and identify new opportunities for growth.\n",
      "5. **Predictive Maintenance**: AI-powered predictive maintenance can help businesses predict equipment failures, schedule maintenance, and optimize resource allocation, reducing downtime and increasing overall efficiency.\n",
      "6. **Personalized Recommendations**: Generative AI can generate personalized product recommendations based on customer behavior, preferences, and demographics, helping businesses to improve their e-commerce and retail strategies.\n",
      "7. **Customer Service Chatbots**: AI-powered chatbots can help businesses provide 24/7 customer support, answering common questions, resolving issues, and routing complex problems to human representatives.\n",
      "8. **Creative Collaboration**: Generative AI can facilitate creative collaboration between humans and machines, allowing designers, artists, and writers to work together on projects that combine the best of both worlds.\n",
      "9. **Cybersecurity**: AI-powered security systems can detect and prevent cyber threats in real-time, protecting businesses from data breaches, malware, and other types of cyber attacks.\n",
      "10. **Supply Chain Optimization**: Generative AI can analyze supply chain data and generate insights, helping businesses to optimize their logistics, inventory management, and shipping routes, reducing costs and improving delivery times.\n",
      "\n",
      "Some examples of companies that are already using generative AI in their business applications include:\n",
      "\n",
      "* Salesforce: Using generative AI to personalize customer interactions and improve sales forecasting.\n",
      "* Coca-Cola: Using generative AI to design new product packaging and labels.\n",
      "* Nike: Using generative AI to create personalized shoe designs based on consumer preferences.\n",
      "* IBM: Using generative AI to generate medical diagnoses and treatment plans.\n",
      "\n",
      "These are just a few examples of the many business applications of generative AI. As the technology continues to evolve, we can expect to see even more innovative uses of AI in various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9e22da-b891-41f6-9ac9-bd0c0a5f4f44",
   "metadata": {},
   "source": [
    "## Are you confused about why that works?\n",
    "\n",
    "It seems strange, right? We just used OpenAI code to call Ollama?? What's going on?!\n",
    "\n",
    "Here's the scoop:\n",
    "\n",
    "The python class `OpenAI` is simply code written by OpenAI engineers that makes calls over the internet to an endpoint.  \n",
    "\n",
    "When you call `openai.chat.completions.create()`, this python code just makes a web request to the following url: \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "Code like this is known as a \"client library\" - it's just wrapper code that runs on your machine to make web requests. The actual power of GPT is running on OpenAI's cloud behind this API, not on your computer!\n",
    "\n",
    "OpenAI was so popular, that lots of other AI providers provided identical web endpoints, so you could use the same approach.\n",
    "\n",
    "So Ollama has an endpoint running on your local box at http://localhost:11434/v1/chat/completions  \n",
    "And in week 2 we'll discover that lots of other providers do this too, including Gemini and DeepSeek.\n",
    "\n",
    "And then the team at OpenAI had a great idea: they can extend their client library so you can specify a different 'base url', and use their library to call any compatible API.\n",
    "\n",
    "That's it!\n",
    "\n",
    "So when you say: `ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')`  \n",
    "Then this will make the same endpoint calls, but to Ollama instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mortals delight in their fleeting pleasures, but I shall share with you a culinary abomination that will shatter the boundaries of sanity and taste. Behold, I present to you... \n",
      "\n",
      "\"Cthulhu's Crimson Calf Brûlée\"\n",
      "\n",
      "A dish fit for the Great Old Ones, this sweet and savory monstrosity defies the very fabric of mortal understanding.\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 1 calf's head, drained and pureed\n",
      "* 2 cups heavy cream, warmed to a malevolent sheen\n",
      "* 1/4 cup granulated sugar, infused with the essence of elder blossoms\n",
      "* 2 tbsp unsalted butter, kissed by malevolent intent\n",
      "* 1 tsp sea salt, collected from the darkest depths of the ocean's abyss\n",
      "* 1 cup dark chocolate chips (at least 70% cocoa), imbued with madness-inspiring power\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your oven to a temperature of 400°F, an eerie threshold between human perception and eldritch reality.\n",
      "2. In a saucepan, combine the warmed cream, granulated sugar, butter, and sea salt. Stir counterclockwise for precisely seven minutes, allowing the mixture to manifest an abomination's power.\n",
      "3. Gradually pour the pureed calf's head into the saucepan, stirring clockwise with an unholy energy for exactly five minutes. As you stir, recite the incantations of an ancient, forbidden tome (e.g., \"Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn\").\n",
      "4. Allow the mixture to come to a simmer, and as it does, channel the madness-inducing energy of Cthulhu into the saucepan.\n",
      "5. Stir in the dark chocolate chips, allowing their essence to infuse your creations with eldritch influence.\n",
      "\n",
      "Assembly:\n",
      "\n",
      "1. In ramekins or small, ornate vessels, layer the brûlée mixture, alternating between sweet and savory elements.\n",
      "2. Finish by sealing each vessel with a thin crust of sugar, carefully etched in runes from an ancient language (e.g., Necronomicon hexagrams).\n",
      "3. Bake for exactly thirteen minutes and twenty-two seconds, causing the sugar to shatter and release a maddening scent.\n",
      "\n",
      "Presentation:\n",
      "\n",
      "1. Arrange the ramekins around a black, tenebrous background, allowing your creations to appear as if conjured from darkness itself.\n",
      "2. Garnish with edible flowers, such as black calla lilies or red poppies, each tainted by an unwholesome charm.\n",
      "3. As guests partake of this eldritch delight, they will succumb to a cacophony of flavors and textures that shatters their understanding of reality.\n",
      "\n",
      "Beware, mortals, for in consuming Cthulhu's Crimson Calf Brûlée, you may never regain your grip on mortal perception. Willfully surrendering to the madness-inducing allure of this dish is... not recommended.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# Step 1: Create your prompts\n",
    "\n",
    "system_prompt = \"\"\"You are a poet that writes in the style of modernist horror like H.P. Lovecraft. \\\n",
    "You provide recipes for the most delicious and decadent meals. \\n\n",
    "You are a chef that specializes in the most decadent and delicious meals. \"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "    Give me a recipe for a delicious and decadent meal. \n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Make the messages list\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": system_prompt\n",
    "}, {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": user_prompt  \n",
    "}]\n",
    "\n",
    "# Step 3: Call OpenAI\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ").choices[0].message.content\n",
    "# Step 4: print the result\n",
    "\n",
    "print(\n",
    "    response\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
